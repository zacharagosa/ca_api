{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f253c5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.cloud import geminidataanalytics\n",
    "from google.adk.agents import Agent\n",
    "# Removed VertexAiCodeExecutor and other executor imports\n",
    "from google.adk.tools import agent_tool\n",
    "import vertexai\n",
    "# from vertexai import agent_engines # Kept for potential vertexai.init\n",
    "# from vertexai.preview import reasoning_engines # Kept for potential vertexai.init\n",
    "import json # Import json for potentially parsing the data\n",
    "\n",
    "def get_insights(question: str):\n",
    "    \"\"\"Queries the Conversational Analytics API using a question as input.\n",
    "\n",
    "  Use this tool to generate the data for data insights.\n",
    "\n",
    "  Args:\n",
    "      question: The question to post to the API.\n",
    "\n",
    "  Returns:\n",
    "      A dictionary containing the status of the operation and the insights from\n",
    "      the API, categorized by type (e.g., text_insights, data_insights) to make\n",
    "      the output easier for an LLM to understand and process.\n",
    "  \"\"\"\n",
    "\n",
    "    data_chat_client = geminidataanalytics.DataChatServiceClient()\n",
    "    lookml_model = \"gaming\"\n",
    "    explore = \"events\"\n",
    "\n",
    "    # User Credentials\n",
    "    looker_client_id = \"9cR2K4JdGYjZCBCm6HGs\"\n",
    "    looker_client_secret = \"8YP9CWFVhdzxF2dvPsyJhQdR\"\n",
    "    # Required only for Looker PUBLIC instance\n",
    "    looker_instance_uri = \"https://3417a175-fe20-4370-974f-2f2b535340ab.looker.app\"\n",
    "\n",
    "    credentials = geminidataanalytics.Credentials(\n",
    "        oauth=geminidataanalytics.OAuthCredentials(\n",
    "            secret=geminidataanalytics.OAuthCredentials.SecretBased(\n",
    "                client_id=looker_client_id, client_secret=looker_client_secret\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    looker_explore_reference = geminidataanalytics.LookerExploreReference(\n",
    "        looker_instance_uri=looker_instance_uri, lookml_model=lookml_model, explore=explore\n",
    "    )\n",
    "\n",
    "    # Connect to your Looker datasource\n",
    "    datasource_references = geminidataanalytics.DatasourceReferences(\n",
    "        looker=geminidataanalytics.LookerExploreReferences(\n",
    "            explore_references=[looker_explore_reference],\n",
    "            credentials=credentials # Note: uncomment this only in case of stateless chat via inline context\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    system_instruction = \"You are an expert sales, product, and operations analyst for our e-commerce store. Your primary function is to answer questions by querying the 'Order Items' Explore. Always be concise and data-driven. Never generate a chart.\"\n",
    "\n",
    "    # Context set-up for 'Chat using Inline Context'\n",
    "    inline_context = geminidataanalytics.Context(\n",
    "        system_instruction=system_instruction,\n",
    "        datasource_references=datasource_references,\n",
    "        options=geminidataanalytics.ConversationOptions(\n",
    "            analysis=geminidataanalytics.AnalysisOptions(\n",
    "                python=geminidataanalytics.AnalysisOptions.Python(\n",
    "                    enabled=False\n",
    "                )  # if wanting to use advanced analysis with python\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    billing_project = \"update\"\n",
    "\n",
    "    messages = [geminidataanalytics.Message()]\n",
    "    messages[0].user_message.text = question\n",
    "\n",
    "    request = geminidataanalytics.ChatRequest(\n",
    "        inline_context=inline_context,\n",
    "        parent=f\"projects/{billing_project}/locations/global\",\n",
    "        messages=messages,\n",
    "    )\n",
    "\n",
    "    # Make the request\n",
    "    stream = data_chat_client.chat(request=request)\n",
    "\n",
    "    # Categorize insights from the stream for a more descriptive output\n",
    "    text_insights = []\n",
    "    schema_insights = []\n",
    "    data_insights = []\n",
    "    # chart_insights = [] # No longer needed\n",
    "\n",
    "    for item in stream:\n",
    "        if item._pb.WhichOneof(\"kind\") == \"system_message\":\n",
    "            message_dict = geminidataanalytics.SystemMessage.to_dict(\n",
    "                item.system_message\n",
    "            )\n",
    "            if \"text\" in message_dict:\n",
    "                text_insights.append(message_dict[\"text\"])\n",
    "            elif \"schema\" in message_dict:\n",
    "                schema_insights.append(message_dict[\"schema\"])\n",
    "            elif \"data\" in message_dict:\n",
    "                data_insights.append(message_dict[\"data\"])\n",
    "            # elif \"chart\" in message_dict: # chart_insights removed\n",
    "            #     chart_insights.append(message_dict[\"chart\"])\n",
    "\n",
    "    # Build a descriptive response dictionary that is easier for the LLM to parse\n",
    "    response = {\"status\": \"success\"}\n",
    "    if text_insights:\n",
    "        response[\"text_insights\"] = text_insights\n",
    "    if schema_insights:\n",
    "        response[\"schema_insights\"] = schema_insights\n",
    "    if data_insights:\n",
    "        response[\"data_insights\"] = data_insights\n",
    "    # chart_insights removed from response\n",
    "    print(response)\n",
    "    return response\n",
    "\n",
    "# Agent to get data insights\n",
    "data_agent = Agent(\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    name=\"DataAgent\",\n",
    "    description=\"Use this agent to get data insights about orders, sales, and e-commerce from the Cymbal Pets Superstore.\",\n",
    "    instruction = \"\"\"You are an agent that retrieves raw data. The tool 'get_insights' queries a governed semantic layer.\n",
    "    Your task is to call the 'get_insights' tool with the user's question.\n",
    "    From the tool's dictionary output, find the 'data_insights' list. Within that list, find the dictionary that contains a 'result' key.\n",
    "    Extract the list of records from the 'data' key which is inside 'result'.\n",
    "    Return this list of records as a JSON string. Do not add any other text or summarization.\n",
    "    \"\"\",\n",
    "    tools=[get_insights],\n",
    ")\n",
    "\n",
    "# visualization_agent has been removed.\n",
    "\n",
    "# Root agent to orchestrate the sub-agents\n",
    "root_agent = Agent(\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    name=\"RootAgent\",\n",
    "    instruction=\"\"\"You are a helpful data analysis assistant. Your goal is to answer user questions by retrieving data.\n",
    "\n",
    "    Your workflow is as follows:\n",
    "    1. When the user asks a question about data, use the `DataAgent` tool to retrieve the necessary data. The `DataAgent` will return a JSON string of the raw data.\n",
    "    2. Briefly summarize the findings from the JSON data provided by DataAgent. Present key results clearly. Use a markdown table if the data is tabular. Do not offer to create any visualizations or charts.\n",
    "    \"\"\",\n",
    "    tools=[\n",
    "        agent_tool.AgentTool(agent=data_agent),\n",
    "        # agent_tool.AgentTool(agent=visualization_agent), # Removed visualization tool\n",
    "    ],\n",
    ")\n",
    "\n",
    "PROJECT_ID = \"aragosalooker\"\n",
    "LOCATION = \"us-central1\"\n",
    "STAGING_BUCKET = \"ca_api\"\n",
    "\n",
    "vertexai.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=LOCATION,\n",
    "    staging_bucket=STAGING_BUCKET,\n",
    ")\n",
    "\n",
    "app = reasoning_engines.AdkApp(\n",
    "    agent=root_agent,\n",
    "    \n",
    "    enable_tracing=True,\n",
    ")\n",
    "\n",
    "remote_app = agent_engines.create(\n",
    "    agent_engine=app,\n",
    "    requirements=[\n",
    "        \"google-cloud-aiplatform[adk,agent_engines]\",\n",
    "        \"google-cloud-geminidataanalytics\",\n",
    "    ],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
